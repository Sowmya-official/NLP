{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text-Summarization-using-SPacy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZWQwpGglpK6T5Fxoj3yYy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sowmya-official/NLP/blob/main/Text_Summarization_using_SPacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zvlb8BFilqQ8"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking text for summarization\n",
        "text = 'Recently, machine learning (ML) has become very widespread in research and has been incorporated in a variety of applications, including text mining, spam detection, video recommendation, image classifcation, and multimedia concept retrieval [1–6]. Among the diferent ML algorithms, deep learning (DL) is very commonly employed in these applications [7–9]. Another name for DL is representation learning (RL). Te continuing appearance of novel studies in the felds of deep and distributed learning is due to both the unpredictable growth in the ability to obtain data and the amazing progress made in the hardware technologies, e.g. High Performance Computing (HPC) [10]. DL is derived from the conventional neural network but considerably outperforms its predecessors. Moreover, DL employs transformations and graph technologies simultaneously in order to build up multi-layer learning models. Te most recently developed DL techniques have obtained good outstanding performance across a variety of applications, including audio and speech processing, visual data processing, natural language processing (NLP), among others [11–14]. Usually, the efectiveness of an ML algorithm is highly dependent on the integrity of the input-data representation. It has been shown that a suitable data representation provides an improved performance when compared to a poor data representation. Tus, a signifcant research trend in ML for many years has been feature engineering, which has informed numerous research studies. Tis approach aims at constructing features from raw data. In addition, it is extremely feld-specifc and frequently requires sizable human efort. For instance, several types of features were introduced and compared in the computer vision context, such as, histogram of oriented gradients (HOG) [15], scaleinvariant feature transform (SIFT) [16], and bag of words (BoW) [17]. As soon as a novel feature is introduced and is found to perform well, it becomes a new research direction that is pursued over multiple decades. Relatively speaking, feature extraction is achieved in an automatic way throughout the DL algorithms. Tis encourages researchers to extract discriminative features using the smallest possible amount of human efort and feld knowledge [18]. Tese algorithms have a multi-layer data representation architecture, in which the frst layers extract the low-level features while the last layers extract the high-level features. Note that artifcial intelligence (AI) originally inspired this type of architecture, which simulates the process that occurs in core sensorial regions within the human brain. Using diferent scenes, the human brain can automatically extract data representation. More specifcally, the output of this process is the classifed objects, while the received scene information represents the input. Tis process simulates the working methodology of the human brain. Tus, it emphasizes the main beneft of DL. In the feld of ML, DL, due to its considerable success, is currently one of the most prominent research trends. In this paper, an overview of DL is presented that adopts various perspectives such as the main concepts, architectures, challenges, applications, computational tools and evolution matrix. Convolutional neural network (CNN) is one of the most popular and used of DL networks [19, 20]. Because of CNN, DL is very popular nowadays. Te main advantage of CNN compared to its predecessors is that it automatically detects the signifcant features without any human supervision which made it the most used. Terefore, we have dug in deep with CNN by presenting the main Alzubaidi et al. J Big Data (2021) 8:53 Page 3 of 74 components of it. Furthermore, we have elaborated in detail the most common CNN architectures, starting with the AlexNet network and ending with the High-Resolution network (HR.Net). Several published DL review papers have been presented in the last few years. However, all of them have only been addressed one side focusing on one application or topic such as the review of CNN architectures [21], DL for classifcation of plant diseases [22], DL for object detection [23], DL applications in medical image analysis [24], and etc. Although these reviews present good topics, they do not provide a full understanding of DL topics such as concepts, detailed research gaps, computational tools, and DL applications.'"
      ],
      "metadata": {
        "id": "2yLdFbHCmBjT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of stop words\n",
        "stopwords = list( STOP_WORDS)\n",
        "stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nU7OyDXOmI4E",
        "outputId": "2277b821-8307-44c3-d0a3-db7f9da72bab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cannot',\n",
              " 'us',\n",
              " 'go',\n",
              " 'been',\n",
              " 'third',\n",
              " 'everyone',\n",
              " 'over',\n",
              " 'formerly',\n",
              " 'such',\n",
              " 'the',\n",
              " 'themselves',\n",
              " 'that',\n",
              " 'someone',\n",
              " 'wherein',\n",
              " 'anyway',\n",
              " 'hereafter',\n",
              " 'via',\n",
              " 'then',\n",
              " 'yourselves',\n",
              " 'next',\n",
              " 'who',\n",
              " 'his',\n",
              " '‘ll',\n",
              " 'amongst',\n",
              " 'down',\n",
              " 'therein',\n",
              " 'done',\n",
              " 'doing',\n",
              " 'at',\n",
              " 'first',\n",
              " 'get',\n",
              " 'either',\n",
              " 'during',\n",
              " \"'ll\",\n",
              " 'every',\n",
              " 'was',\n",
              " 'anyhow',\n",
              " '’ll',\n",
              " 'with',\n",
              " 'our',\n",
              " 'within',\n",
              " 'something',\n",
              " 'by',\n",
              " 'anyone',\n",
              " 're',\n",
              " 'where',\n",
              " 'several',\n",
              " 'hundred',\n",
              " 'which',\n",
              " 'five',\n",
              " 'each',\n",
              " 'hence',\n",
              " \"'d\",\n",
              " 'three',\n",
              " 'quite',\n",
              " 'again',\n",
              " 'whereafter',\n",
              " 'twenty',\n",
              " 'part',\n",
              " 'more',\n",
              " 'should',\n",
              " 'nor',\n",
              " 'whatever',\n",
              " 'once',\n",
              " 'herein',\n",
              " 'beyond',\n",
              " 'others',\n",
              " 'really',\n",
              " 'name',\n",
              " 'whence',\n",
              " 'be',\n",
              " 'nobody',\n",
              " 'here',\n",
              " 'until',\n",
              " 'this',\n",
              " 'have',\n",
              " 'i',\n",
              " 'their',\n",
              " 'except',\n",
              " 'together',\n",
              " 'hereby',\n",
              " 'though',\n",
              " 'eight',\n",
              " 'without',\n",
              " 'sometime',\n",
              " 'or',\n",
              " 'hereupon',\n",
              " 'for',\n",
              " 'nothing',\n",
              " 'your',\n",
              " 'among',\n",
              " 'latter',\n",
              " 'top',\n",
              " 'whenever',\n",
              " 'various',\n",
              " 'say',\n",
              " 'always',\n",
              " 'they',\n",
              " 'upon',\n",
              " 'beforehand',\n",
              " 'make',\n",
              " 'between',\n",
              " 'its',\n",
              " 'made',\n",
              " 'yourself',\n",
              " 'somehow',\n",
              " 'wherever',\n",
              " 'sixty',\n",
              " 'seem',\n",
              " 'are',\n",
              " 'can',\n",
              " 'unless',\n",
              " 'in',\n",
              " 'ours',\n",
              " 'thereafter',\n",
              " 'moreover',\n",
              " 'namely',\n",
              " 'itself',\n",
              " 'somewhere',\n",
              " 'her',\n",
              " '’s',\n",
              " 'last',\n",
              " 'a',\n",
              " 'what',\n",
              " 'towards',\n",
              " 'does',\n",
              " 'nine',\n",
              " 'hers',\n",
              " 'otherwise',\n",
              " 'n‘t',\n",
              " 'against',\n",
              " 'front',\n",
              " 'much',\n",
              " 'yet',\n",
              " 'myself',\n",
              " 'whom',\n",
              " 'former',\n",
              " 'than',\n",
              " 'were',\n",
              " 'elsewhere',\n",
              " 'take',\n",
              " '’m',\n",
              " 'well',\n",
              " 'whereby',\n",
              " 'anywhere',\n",
              " 'becomes',\n",
              " 'further',\n",
              " 'rather',\n",
              " 'perhaps',\n",
              " 'own',\n",
              " 'keep',\n",
              " 'whose',\n",
              " 'all',\n",
              " 'below',\n",
              " 'see',\n",
              " 'an',\n",
              " 'as',\n",
              " '’ve',\n",
              " 'beside',\n",
              " 'many',\n",
              " 'side',\n",
              " 'just',\n",
              " 'move',\n",
              " 'none',\n",
              " 'even',\n",
              " 'would',\n",
              " 'if',\n",
              " 'mine',\n",
              " 'fifty',\n",
              " 'serious',\n",
              " 'forty',\n",
              " 'is',\n",
              " 'thereupon',\n",
              " 'afterwards',\n",
              " 'whereas',\n",
              " 'ca',\n",
              " 'about',\n",
              " 'two',\n",
              " 'almost',\n",
              " 'mostly',\n",
              " 'we',\n",
              " 'could',\n",
              " 'on',\n",
              " '‘s',\n",
              " 'bottom',\n",
              " '‘ve',\n",
              " 'fifteen',\n",
              " 'four',\n",
              " 'put',\n",
              " 'noone',\n",
              " 'became',\n",
              " 'above',\n",
              " '‘re',\n",
              " 'therefore',\n",
              " 'another',\n",
              " 'under',\n",
              " 'any',\n",
              " 'he',\n",
              " 'herself',\n",
              " \"'s\",\n",
              " 'him',\n",
              " 'six',\n",
              " 'used',\n",
              " 'neither',\n",
              " 'along',\n",
              " 'will',\n",
              " \"'m\",\n",
              " 'and',\n",
              " 'behind',\n",
              " 'ourselves',\n",
              " 'up',\n",
              " 'am',\n",
              " 'onto',\n",
              " 'everywhere',\n",
              " 'often',\n",
              " 'latterly',\n",
              " 'while',\n",
              " 'after',\n",
              " 'indeed',\n",
              " 'empty',\n",
              " 'out',\n",
              " 'please',\n",
              " 'show',\n",
              " 'because',\n",
              " \"'ve\",\n",
              " 'ever',\n",
              " 'so',\n",
              " 'into',\n",
              " 'thence',\n",
              " 'thereby',\n",
              " 'most',\n",
              " 'throughout',\n",
              " \"n't\",\n",
              " 'toward',\n",
              " 'to',\n",
              " 'full',\n",
              " 'sometimes',\n",
              " 'become',\n",
              " \"'re\",\n",
              " 'becoming',\n",
              " 'may',\n",
              " 'but',\n",
              " 'through',\n",
              " 'anything',\n",
              " 'these',\n",
              " 'still',\n",
              " 'n’t',\n",
              " 'besides',\n",
              " '‘m',\n",
              " '’re',\n",
              " 'of',\n",
              " 'same',\n",
              " 'since',\n",
              " 'seemed',\n",
              " 'some',\n",
              " '‘d',\n",
              " 'off',\n",
              " 'thus',\n",
              " 'yours',\n",
              " 'however',\n",
              " 'eleven',\n",
              " 'per',\n",
              " 'my',\n",
              " 'before',\n",
              " 'also',\n",
              " 'everything',\n",
              " 'it',\n",
              " 'himself',\n",
              " 'around',\n",
              " 'seems',\n",
              " 'when',\n",
              " 'already',\n",
              " 'not',\n",
              " 'other',\n",
              " 'using',\n",
              " 'how',\n",
              " 'never',\n",
              " 'regarding',\n",
              " 'alone',\n",
              " 'both',\n",
              " 'whether',\n",
              " 'too',\n",
              " 'thru',\n",
              " 'whoever',\n",
              " 'might',\n",
              " 'did',\n",
              " 'she',\n",
              " 'amount',\n",
              " 'do',\n",
              " 'whither',\n",
              " 'nowhere',\n",
              " 'back',\n",
              " 'why',\n",
              " 'there',\n",
              " 'few',\n",
              " 'give',\n",
              " 'twelve',\n",
              " 'nevertheless',\n",
              " 'them',\n",
              " 'very',\n",
              " 'now',\n",
              " '’d',\n",
              " 'across',\n",
              " 'due',\n",
              " 'one',\n",
              " 'least',\n",
              " 'ten',\n",
              " 'being',\n",
              " 'those',\n",
              " 'must',\n",
              " 'call',\n",
              " 'whereupon',\n",
              " 'meanwhile',\n",
              " 'although',\n",
              " 'no',\n",
              " 'enough',\n",
              " 'else',\n",
              " 'only',\n",
              " 'from',\n",
              " 'had',\n",
              " 'less',\n",
              " 'you',\n",
              " 'whole',\n",
              " 'seeming',\n",
              " 'me',\n",
              " 'has']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pass document into spacy and store in \"doc\" object\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "_70415OJmawn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization is the process of tokenizing or splitting a string, text into a list of tokens. One can think of token as parts like a word is a token in a sentence, \n",
        "#and a sentence is a token in a paragraph.\n",
        "\n",
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvI59_Yzmg4K",
        "outputId": "1a9b0d87-73c1-4a0c-992a-abba24e6e44c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Recently', ',', 'machine', 'learning', '(', 'ML', ')', 'has', 'become', 'very', 'widespread', 'in', 'research', 'and', 'has', 'been', 'incorporated', 'in', 'a', 'variety', 'of', 'applications', ',', 'including', 'text', 'mining', ',', 'spam', 'detection', ',', 'video', 'recommendation', ',', 'image', 'classifcation', ',', 'and', 'multimedia', 'concept', 'retrieval', '[', '1–6', ']', '.', 'Among', 'the', 'diferent', 'ML', 'algorithms', ',', 'deep', 'learning', '(', 'DL', ')', 'is', 'very', 'commonly', 'employed', 'in', 'these', 'applications', '[', '7–9', ']', '.', 'Another', 'name', 'for', 'DL', 'is', 'representation', 'learning', '(', 'RL', ')', '.', 'Te', 'continuing', 'appearance', 'of', 'novel', 'studies', 'in', 'the', 'felds', 'of', 'deep', 'and', 'distributed', 'learning', 'is', 'due', 'to', 'both', 'the', 'unpredictable', 'growth', 'in', 'the', 'ability', 'to', 'obtain', 'data', 'and', 'the', 'amazing', 'progress', 'made', 'in', 'the', 'hardware', 'technologies', ',', 'e.g.', 'High', 'Performance', 'Computing', '(', 'HPC', ')', '[', '10', ']', '.', 'DL', 'is', 'derived', 'from', 'the', 'conventional', 'neural', 'network', 'but', 'considerably', 'outperforms', 'its', 'predecessors', '.', 'Moreover', ',', 'DL', 'employs', 'transformations', 'and', 'graph', 'technologies', 'simultaneously', 'in', 'order', 'to', 'build', 'up', 'multi', '-', 'layer', 'learning', 'models', '.', 'Te', 'most', 'recently', 'developed', 'DL', 'techniques', 'have', 'obtained', 'good', 'outstanding', 'performance', 'across', 'a', 'variety', 'of', 'applications', ',', 'including', 'audio', 'and', 'speech', 'processing', ',', 'visual', 'data', 'processing', ',', 'natural', 'language', 'processing', '(', 'NLP', ')', ',', 'among', 'others', '[', '11–14', ']', '.', 'Usually', ',', 'the', 'efectiveness', 'of', 'an', 'ML', 'algorithm', 'is', 'highly', 'dependent', 'on', 'the', 'integrity', 'of', 'the', 'input', '-', 'data', 'representation', '.', 'It', 'has', 'been', 'shown', 'that', 'a', 'suitable', 'data', 'representation', 'provides', 'an', 'improved', 'performance', 'when', 'compared', 'to', 'a', 'poor', 'data', 'representation', '.', 'Tus', ',', 'a', 'signifcant', 'research', 'trend', 'in', 'ML', 'for', 'many', 'years', 'has', 'been', 'feature', 'engineering', ',', 'which', 'has', 'informed', 'numerous', 'research', 'studies', '.', 'Tis', 'approach', 'aims', 'at', 'constructing', 'features', 'from', 'raw', 'data', '.', 'In', 'addition', ',', 'it', 'is', 'extremely', 'feld', '-', 'specifc', 'and', 'frequently', 'requires', 'sizable', 'human', 'efort', '.', 'For', 'instance', ',', 'several', 'types', 'of', 'features', 'were', 'introduced', 'and', 'compared', 'in', 'the', 'computer', 'vision', 'context', ',', 'such', 'as', ',', 'histogram', 'of', 'oriented', 'gradients', '(', 'HOG', ')', '[', '15', ']', ',', 'scaleinvariant', 'feature', 'transform', '(', 'SIFT', ')', '[', '16', ']', ',', 'and', 'bag', 'of', 'words', '(', 'BoW', ')', '[', '17', ']', '.', 'As', 'soon', 'as', 'a', 'novel', 'feature', 'is', 'introduced', 'and', 'is', 'found', 'to', 'perform', 'well', ',', 'it', 'becomes', 'a', 'new', 'research', 'direction', 'that', 'is', 'pursued', 'over', 'multiple', 'decades', '.', 'Relatively', 'speaking', ',', 'feature', 'extraction', 'is', 'achieved', 'in', 'an', 'automatic', 'way', 'throughout', 'the', 'DL', 'algorithms', '.', 'Tis', 'encourages', 'researchers', 'to', 'extract', 'discriminative', 'features', 'using', 'the', 'smallest', 'possible', 'amount', 'of', 'human', 'efort', 'and', 'feld', 'knowledge', '[', '18', ']', '.', 'Tese', 'algorithms', 'have', 'a', 'multi', '-', 'layer', 'data', 'representation', 'architecture', ',', 'in', 'which', 'the', 'frst', 'layers', 'extract', 'the', 'low', '-', 'level', 'features', 'while', 'the', 'last', 'layers', 'extract', 'the', 'high', '-', 'level', 'features', '.', 'Note', 'that', 'artifcial', 'intelligence', '(', 'AI', ')', 'originally', 'inspired', 'this', 'type', 'of', 'architecture', ',', 'which', 'simulates', 'the', 'process', 'that', 'occurs', 'in', 'core', 'sensorial', 'regions', 'within', 'the', 'human', 'brain', '.', 'Using', 'diferent', 'scenes', ',', 'the', 'human', 'brain', 'can', 'automatically', 'extract', 'data', 'representation', '.', 'More', 'specifcally', ',', 'the', 'output', 'of', 'this', 'process', 'is', 'the', 'classifed', 'objects', ',', 'while', 'the', 'received', 'scene', 'information', 'represents', 'the', 'input', '.', 'Tis', 'process', 'simulates', 'the', 'working', 'methodology', 'of', 'the', 'human', 'brain', '.', 'Tus', ',', 'it', 'emphasizes', 'the', 'main', 'beneft', 'of', 'DL', '.', 'In', 'the', 'feld', 'of', 'ML', ',', 'DL', ',', 'due', 'to', 'its', 'considerable', 'success', ',', 'is', 'currently', 'one', 'of', 'the', 'most', 'prominent', 'research', 'trends', '.', 'In', 'this', 'paper', ',', 'an', 'overview', 'of', 'DL', 'is', 'presented', 'that', 'adopts', 'various', 'perspectives', 'such', 'as', 'the', 'main', 'concepts', ',', 'architectures', ',', 'challenges', ',', 'applications', ',', 'computational', 'tools', 'and', 'evolution', 'matrix', '.', 'Convolutional', 'neural', 'network', '(', 'CNN', ')', 'is', 'one', 'of', 'the', 'most', 'popular', 'and', 'used', 'of', 'DL', 'networks', '[', '19', ',', '20', ']', '.', 'Because', 'of', 'CNN', ',', 'DL', 'is', 'very', 'popular', 'nowadays', '.', 'Te', 'main', 'advantage', 'of', 'CNN', 'compared', 'to', 'its', 'predecessors', 'is', 'that', 'it', 'automatically', 'detects', 'the', 'signifcant', 'features', 'without', 'any', 'human', 'supervision', 'which', 'made', 'it', 'the', 'most', 'used', '.', 'Terefore', ',', 'we', 'have', 'dug', 'in', 'deep', 'with', 'CNN', 'by', 'presenting', 'the', 'main', 'Alzubaidi', 'et', 'al', '.', 'J', 'Big', 'Data', '(', '2021', ')', '8:53', 'Page', '3', 'of', '74', 'components', 'of', 'it', '.', 'Furthermore', ',', 'we', 'have', 'elaborated', 'in', 'detail', 'the', 'most', 'common', 'CNN', 'architectures', ',', 'starting', 'with', 'the', 'AlexNet', 'network', 'and', 'ending', 'with', 'the', 'High', '-', 'Resolution', 'network', '(', 'HR.Net', ')', '.', 'Several', 'published', 'DL', 'review', 'papers', 'have', 'been', 'presented', 'in', 'the', 'last', 'few', 'years', '.', 'However', ',', 'all', 'of', 'them', 'have', 'only', 'been', 'addressed', 'one', 'side', 'focusing', 'on', 'one', 'application', 'or', 'topic', 'such', 'as', 'the', 'review', 'of', 'CNN', 'architectures', '[', '21', ']', ',', 'DL', 'for', 'classifcation', 'of', 'plant', 'diseases', '[', '22', ']', ',', 'DL', 'for', 'object', 'detection', '[', '23', ']', ',', 'DL', 'applications', 'in', 'medical', 'image', 'analysis', '[', '24', ']', ',', 'and', 'etc', '.', 'Although', 'these', 'reviews', 'present', 'good', 'topics', ',', 'they', 'do', 'not', 'provide', 'a', 'full', 'understanding', 'of', 'DL', 'topics', 'such', 'as', 'concepts', ',', 'detailed', 'research', 'gaps', ',', 'computational', 'tools', ',', 'and', 'DL', 'applications', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add \\n to the punchuvation list\n",
        "punctuation = punctuation + '\\n' + '\\n\\n'\n",
        "punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "w06l_XapmoTm",
        "outputId": "2b4104f4-30d3-42c3-9e15-ed4fc90fad3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing a dictionary for word frequencies\n",
        "word_frequencies = {}                       # Dictionary Name\n",
        "for word in doc:\n",
        "    if word.text.lower() not in stopwords:\n",
        "        if word.text.lower() not in punctuation:\n",
        "            if word.text not in word_frequencies.keys():   \n",
        "                word_frequencies[word.text] = 1\n",
        "            else:\n",
        "                word_frequencies[word.text] +=1\n",
        "print(word_frequencies)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3kDhm2bmsY9",
        "outputId": "bc9e79d3-e7b2-4872-e58b-d8dd562ff25c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Recently': 1, 'machine': 1, 'learning': 5, 'ML': 5, 'widespread': 1, 'research': 6, 'incorporated': 1, 'variety': 2, 'applications': 6, 'including': 2, 'text': 1, 'mining': 1, 'spam': 1, 'detection': 2, 'video': 1, 'recommendation': 1, 'image': 2, 'classifcation': 2, 'multimedia': 1, 'concept': 1, 'retrieval': 1, '1–6': 1, 'diferent': 2, 'algorithms': 3, 'deep': 3, 'DL': 17, 'commonly': 1, 'employed': 1, '7–9': 1, 'representation': 6, 'RL': 1, 'Te': 3, 'continuing': 1, 'appearance': 1, 'novel': 2, 'studies': 2, 'felds': 1, 'distributed': 1, 'unpredictable': 1, 'growth': 1, 'ability': 1, 'obtain': 1, 'data': 8, 'amazing': 1, 'progress': 1, 'hardware': 1, 'technologies': 2, 'e.g.': 1, 'High': 2, 'Performance': 1, 'Computing': 1, 'HPC': 1, '10': 1, 'derived': 1, 'conventional': 1, 'neural': 2, 'network': 4, 'considerably': 1, 'outperforms': 1, 'predecessors': 2, 'employs': 1, 'transformations': 1, 'graph': 1, 'simultaneously': 1, 'order': 1, 'build': 1, 'multi': 2, 'layer': 2, 'models': 1, 'recently': 1, 'developed': 1, 'techniques': 1, 'obtained': 1, 'good': 2, 'outstanding': 1, 'performance': 2, 'audio': 1, 'speech': 1, 'processing': 3, 'visual': 1, 'natural': 1, 'language': 1, 'NLP': 1, '11–14': 1, 'Usually': 1, 'efectiveness': 1, 'algorithm': 1, 'highly': 1, 'dependent': 1, 'integrity': 1, 'input': 2, 'shown': 1, 'suitable': 1, 'provides': 1, 'improved': 1, 'compared': 3, 'poor': 1, 'Tus': 2, 'signifcant': 2, 'trend': 1, 'years': 2, 'feature': 4, 'engineering': 1, 'informed': 1, 'numerous': 1, 'Tis': 3, 'approach': 1, 'aims': 1, 'constructing': 1, 'features': 6, 'raw': 1, 'addition': 1, 'extremely': 1, 'feld': 3, 'specifc': 1, 'frequently': 1, 'requires': 1, 'sizable': 1, 'human': 6, 'efort': 2, 'instance': 1, 'types': 1, 'introduced': 2, 'computer': 1, 'vision': 1, 'context': 1, 'histogram': 1, 'oriented': 1, 'gradients': 1, 'HOG': 1, '15': 1, 'scaleinvariant': 1, 'transform': 1, 'SIFT': 1, '16': 1, 'bag': 1, 'words': 1, 'BoW': 1, '17': 1, 'soon': 1, 'found': 1, 'perform': 1, 'new': 1, 'direction': 1, 'pursued': 1, 'multiple': 1, 'decades': 1, 'Relatively': 1, 'speaking': 1, 'extraction': 1, 'achieved': 1, 'automatic': 1, 'way': 1, 'encourages': 1, 'researchers': 1, 'extract': 4, 'discriminative': 1, 'smallest': 1, 'possible': 1, 'knowledge': 1, '18': 1, 'Tese': 1, 'architecture': 2, 'frst': 1, 'layers': 2, 'low': 1, 'level': 2, 'high': 1, 'Note': 1, 'artifcial': 1, 'intelligence': 1, 'AI': 1, 'originally': 1, 'inspired': 1, 'type': 1, 'simulates': 2, 'process': 3, 'occurs': 1, 'core': 1, 'sensorial': 1, 'regions': 1, 'brain': 3, 'scenes': 1, 'automatically': 2, 'specifcally': 1, 'output': 1, 'classifed': 1, 'objects': 1, 'received': 1, 'scene': 1, 'information': 1, 'represents': 1, 'working': 1, 'methodology': 1, 'emphasizes': 1, 'main': 4, 'beneft': 1, 'considerable': 1, 'success': 1, 'currently': 1, 'prominent': 1, 'trends': 1, 'paper': 1, 'overview': 1, 'presented': 2, 'adopts': 1, 'perspectives': 1, 'concepts': 2, 'architectures': 3, 'challenges': 1, 'computational': 2, 'tools': 2, 'evolution': 1, 'matrix': 1, 'Convolutional': 1, 'CNN': 6, 'popular': 2, 'networks': 1, '19': 1, '20': 1, 'nowadays': 1, 'advantage': 1, 'detects': 1, 'supervision': 1, 'Terefore': 1, 'dug': 1, 'presenting': 1, 'Alzubaidi': 1, 'et': 1, 'al': 1, 'J': 1, 'Big': 1, 'Data': 1, '2021': 1, '8:53': 1, 'Page': 1, '3': 1, '74': 1, 'components': 1, 'Furthermore': 1, 'elaborated': 1, 'detail': 1, 'common': 1, 'starting': 1, 'AlexNet': 1, 'ending': 1, 'Resolution': 1, 'HR.Net': 1, 'published': 1, 'review': 2, 'papers': 1, 'addressed': 1, 'focusing': 1, 'application': 1, 'topic': 1, '21': 1, 'plant': 1, 'diseases': 1, '22': 1, 'object': 1, '23': 1, 'medical': 1, 'analysis': 1, '24': 1, 'etc': 1, 'reviews': 1, 'present': 1, 'topics': 2, 'provide': 1, 'understanding': 1, 'detailed': 1, 'gaps': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_frequcncy = max(word_frequencies.values())\n"
      ],
      "metadata": {
        "id": "qO_G7frRmx1N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a Dictionay for sentences and its normalized frequencies\n",
        "\n",
        "# Maximum repeated word in the document seemd  - data\n",
        "max_frequcncy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU5Hq4mom7Ot",
        "outputId": "cd53237f-17c1-4892-b4ba-bf417d2fec71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the word frencies\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = word_frequencies[word]/max_frequcncy\n",
        "print(word_frequencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSYMY4vbnExV",
        "outputId": "36ff2288-0bc3-4b7a-b202-f9bdfaf8bf76"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Recently': 0.058823529411764705, 'machine': 0.058823529411764705, 'learning': 0.29411764705882354, 'ML': 0.29411764705882354, 'widespread': 0.058823529411764705, 'research': 0.35294117647058826, 'incorporated': 0.058823529411764705, 'variety': 0.11764705882352941, 'applications': 0.35294117647058826, 'including': 0.11764705882352941, 'text': 0.058823529411764705, 'mining': 0.058823529411764705, 'spam': 0.058823529411764705, 'detection': 0.11764705882352941, 'video': 0.058823529411764705, 'recommendation': 0.058823529411764705, 'image': 0.11764705882352941, 'classifcation': 0.11764705882352941, 'multimedia': 0.058823529411764705, 'concept': 0.058823529411764705, 'retrieval': 0.058823529411764705, '1–6': 0.058823529411764705, 'diferent': 0.11764705882352941, 'algorithms': 0.17647058823529413, 'deep': 0.17647058823529413, 'DL': 1.0, 'commonly': 0.058823529411764705, 'employed': 0.058823529411764705, '7–9': 0.058823529411764705, 'representation': 0.35294117647058826, 'RL': 0.058823529411764705, 'Te': 0.17647058823529413, 'continuing': 0.058823529411764705, 'appearance': 0.058823529411764705, 'novel': 0.11764705882352941, 'studies': 0.11764705882352941, 'felds': 0.058823529411764705, 'distributed': 0.058823529411764705, 'unpredictable': 0.058823529411764705, 'growth': 0.058823529411764705, 'ability': 0.058823529411764705, 'obtain': 0.058823529411764705, 'data': 0.47058823529411764, 'amazing': 0.058823529411764705, 'progress': 0.058823529411764705, 'hardware': 0.058823529411764705, 'technologies': 0.11764705882352941, 'e.g.': 0.058823529411764705, 'High': 0.11764705882352941, 'Performance': 0.058823529411764705, 'Computing': 0.058823529411764705, 'HPC': 0.058823529411764705, '10': 0.058823529411764705, 'derived': 0.058823529411764705, 'conventional': 0.058823529411764705, 'neural': 0.11764705882352941, 'network': 0.23529411764705882, 'considerably': 0.058823529411764705, 'outperforms': 0.058823529411764705, 'predecessors': 0.11764705882352941, 'employs': 0.058823529411764705, 'transformations': 0.058823529411764705, 'graph': 0.058823529411764705, 'simultaneously': 0.058823529411764705, 'order': 0.058823529411764705, 'build': 0.058823529411764705, 'multi': 0.11764705882352941, 'layer': 0.11764705882352941, 'models': 0.058823529411764705, 'recently': 0.058823529411764705, 'developed': 0.058823529411764705, 'techniques': 0.058823529411764705, 'obtained': 0.058823529411764705, 'good': 0.11764705882352941, 'outstanding': 0.058823529411764705, 'performance': 0.11764705882352941, 'audio': 0.058823529411764705, 'speech': 0.058823529411764705, 'processing': 0.17647058823529413, 'visual': 0.058823529411764705, 'natural': 0.058823529411764705, 'language': 0.058823529411764705, 'NLP': 0.058823529411764705, '11–14': 0.058823529411764705, 'Usually': 0.058823529411764705, 'efectiveness': 0.058823529411764705, 'algorithm': 0.058823529411764705, 'highly': 0.058823529411764705, 'dependent': 0.058823529411764705, 'integrity': 0.058823529411764705, 'input': 0.11764705882352941, 'shown': 0.058823529411764705, 'suitable': 0.058823529411764705, 'provides': 0.058823529411764705, 'improved': 0.058823529411764705, 'compared': 0.17647058823529413, 'poor': 0.058823529411764705, 'Tus': 0.11764705882352941, 'signifcant': 0.11764705882352941, 'trend': 0.058823529411764705, 'years': 0.11764705882352941, 'feature': 0.23529411764705882, 'engineering': 0.058823529411764705, 'informed': 0.058823529411764705, 'numerous': 0.058823529411764705, 'Tis': 0.17647058823529413, 'approach': 0.058823529411764705, 'aims': 0.058823529411764705, 'constructing': 0.058823529411764705, 'features': 0.35294117647058826, 'raw': 0.058823529411764705, 'addition': 0.058823529411764705, 'extremely': 0.058823529411764705, 'feld': 0.17647058823529413, 'specifc': 0.058823529411764705, 'frequently': 0.058823529411764705, 'requires': 0.058823529411764705, 'sizable': 0.058823529411764705, 'human': 0.35294117647058826, 'efort': 0.11764705882352941, 'instance': 0.058823529411764705, 'types': 0.058823529411764705, 'introduced': 0.11764705882352941, 'computer': 0.058823529411764705, 'vision': 0.058823529411764705, 'context': 0.058823529411764705, 'histogram': 0.058823529411764705, 'oriented': 0.058823529411764705, 'gradients': 0.058823529411764705, 'HOG': 0.058823529411764705, '15': 0.058823529411764705, 'scaleinvariant': 0.058823529411764705, 'transform': 0.058823529411764705, 'SIFT': 0.058823529411764705, '16': 0.058823529411764705, 'bag': 0.058823529411764705, 'words': 0.058823529411764705, 'BoW': 0.058823529411764705, '17': 0.058823529411764705, 'soon': 0.058823529411764705, 'found': 0.058823529411764705, 'perform': 0.058823529411764705, 'new': 0.058823529411764705, 'direction': 0.058823529411764705, 'pursued': 0.058823529411764705, 'multiple': 0.058823529411764705, 'decades': 0.058823529411764705, 'Relatively': 0.058823529411764705, 'speaking': 0.058823529411764705, 'extraction': 0.058823529411764705, 'achieved': 0.058823529411764705, 'automatic': 0.058823529411764705, 'way': 0.058823529411764705, 'encourages': 0.058823529411764705, 'researchers': 0.058823529411764705, 'extract': 0.23529411764705882, 'discriminative': 0.058823529411764705, 'smallest': 0.058823529411764705, 'possible': 0.058823529411764705, 'knowledge': 0.058823529411764705, '18': 0.058823529411764705, 'Tese': 0.058823529411764705, 'architecture': 0.11764705882352941, 'frst': 0.058823529411764705, 'layers': 0.11764705882352941, 'low': 0.058823529411764705, 'level': 0.11764705882352941, 'high': 0.058823529411764705, 'Note': 0.058823529411764705, 'artifcial': 0.058823529411764705, 'intelligence': 0.058823529411764705, 'AI': 0.058823529411764705, 'originally': 0.058823529411764705, 'inspired': 0.058823529411764705, 'type': 0.058823529411764705, 'simulates': 0.11764705882352941, 'process': 0.17647058823529413, 'occurs': 0.058823529411764705, 'core': 0.058823529411764705, 'sensorial': 0.058823529411764705, 'regions': 0.058823529411764705, 'brain': 0.17647058823529413, 'scenes': 0.058823529411764705, 'automatically': 0.11764705882352941, 'specifcally': 0.058823529411764705, 'output': 0.058823529411764705, 'classifed': 0.058823529411764705, 'objects': 0.058823529411764705, 'received': 0.058823529411764705, 'scene': 0.058823529411764705, 'information': 0.058823529411764705, 'represents': 0.058823529411764705, 'working': 0.058823529411764705, 'methodology': 0.058823529411764705, 'emphasizes': 0.058823529411764705, 'main': 0.23529411764705882, 'beneft': 0.058823529411764705, 'considerable': 0.058823529411764705, 'success': 0.058823529411764705, 'currently': 0.058823529411764705, 'prominent': 0.058823529411764705, 'trends': 0.058823529411764705, 'paper': 0.058823529411764705, 'overview': 0.058823529411764705, 'presented': 0.11764705882352941, 'adopts': 0.058823529411764705, 'perspectives': 0.058823529411764705, 'concepts': 0.11764705882352941, 'architectures': 0.17647058823529413, 'challenges': 0.058823529411764705, 'computational': 0.11764705882352941, 'tools': 0.11764705882352941, 'evolution': 0.058823529411764705, 'matrix': 0.058823529411764705, 'Convolutional': 0.058823529411764705, 'CNN': 0.35294117647058826, 'popular': 0.11764705882352941, 'networks': 0.058823529411764705, '19': 0.058823529411764705, '20': 0.058823529411764705, 'nowadays': 0.058823529411764705, 'advantage': 0.058823529411764705, 'detects': 0.058823529411764705, 'supervision': 0.058823529411764705, 'Terefore': 0.058823529411764705, 'dug': 0.058823529411764705, 'presenting': 0.058823529411764705, 'Alzubaidi': 0.058823529411764705, 'et': 0.058823529411764705, 'al': 0.058823529411764705, 'J': 0.058823529411764705, 'Big': 0.058823529411764705, 'Data': 0.058823529411764705, '2021': 0.058823529411764705, '8:53': 0.058823529411764705, 'Page': 0.058823529411764705, '3': 0.058823529411764705, '74': 0.058823529411764705, 'components': 0.058823529411764705, 'Furthermore': 0.058823529411764705, 'elaborated': 0.058823529411764705, 'detail': 0.058823529411764705, 'common': 0.058823529411764705, 'starting': 0.058823529411764705, 'AlexNet': 0.058823529411764705, 'ending': 0.058823529411764705, 'Resolution': 0.058823529411764705, 'HR.Net': 0.058823529411764705, 'published': 0.058823529411764705, 'review': 0.11764705882352941, 'papers': 0.058823529411764705, 'addressed': 0.058823529411764705, 'focusing': 0.058823529411764705, 'application': 0.058823529411764705, 'topic': 0.058823529411764705, '21': 0.058823529411764705, 'plant': 0.058823529411764705, 'diseases': 0.058823529411764705, '22': 0.058823529411764705, 'object': 0.058823529411764705, '23': 0.058823529411764705, 'medical': 0.058823529411764705, 'analysis': 0.058823529411764705, '24': 0.058823529411764705, 'etc': 0.058823529411764705, 'reviews': 0.058823529411764705, 'present': 0.058823529411764705, 'topics': 0.11764705882352941, 'provide': 0.058823529411764705, 'understanding': 0.058823529411764705, 'detailed': 0.058823529411764705, 'gaps': 0.058823529411764705}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentence Tokenization\n",
        "sentence_tokens = [sent for sent in doc.sents]\n",
        "print(sentence_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAE05xrxnHOf",
        "outputId": "7d13ea36-7f1f-4ce7-cead-77ec31117c53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Recently, machine learning (ML) has become very widespread in research and has been incorporated in a variety of applications, including text mining, spam detection, video recommendation, image classifcation, and multimedia concept retrieval [1–6]., Among the diferent ML algorithms, deep learning (DL) is very commonly employed in these applications [7–9]., Another name for DL is representation learning (RL)., Te continuing appearance of novel studies in the felds of deep and distributed learning is due to both the unpredictable growth in the ability to obtain data and the amazing progress made in the hardware technologies,, e.g. High Performance Computing (HPC), [10]., DL is derived from the conventional neural network but considerably outperforms its predecessors., Moreover, DL employs transformations and graph technologies simultaneously in order to build up multi-layer learning models., Te most recently developed DL techniques have obtained good outstanding performance across a variety of applications, including audio and speech processing, visual data processing, natural language processing (NLP), among others [11–14]., Usually, the efectiveness of an ML algorithm is highly dependent on the integrity of the input-data representation., It has been shown that a suitable data representation provides an improved performance when compared to a poor data representation., Tus, a signifcant research trend in ML for many years has been feature engineering, which has informed numerous research studies., Tis approach aims at constructing features from raw data., In addition, it is extremely feld-specifc and frequently requires sizable human efort., For instance, several types of features were introduced and compared in the computer vision context, such as, histogram of oriented gradients (HOG), [15], scaleinvariant feature transform (SIFT), [16], and bag of words (BoW), [17]., As soon as a novel feature is introduced and is found to perform well, it becomes a new research direction that is pursued over multiple decades., Relatively speaking, feature extraction is achieved in an automatic way throughout the DL algorithms., Tis encourages researchers to extract discriminative features using the smallest possible amount of human efort and feld knowledge [18]., Tese algorithms have a multi-layer data representation architecture, in which the frst layers extract the low-level features while the last layers extract the high-level features., Note that artifcial intelligence (AI) originally inspired this type of architecture, which simulates the process that occurs in core sensorial regions within the human brain., Using diferent scenes, the human brain can automatically extract data representation., More specifcally, the output of this process is the classifed objects, while the received scene information represents the input., Tis process simulates the working methodology of the human brain., Tus, it emphasizes the main beneft of DL., In the feld of ML, DL, due to its considerable success, is currently one of the most prominent research trends., In this paper, an overview of DL is presented that adopts various perspectives such as the main concepts, architectures, challenges, applications, computational tools and evolution matrix., Convolutional neural network (CNN) is one of the most popular and used of DL networks [19, 20]., Because of CNN, DL is very popular nowadays., Te main advantage of CNN compared to its predecessors is that it automatically detects the signifcant features without any human supervision which made it the most used., Terefore, we have dug in deep with CNN by presenting the main Alzubaidi et al., J Big Data (2021), 8:53 Page 3 of 74 components of it., Furthermore, we have elaborated in detail the most common CNN architectures, starting with the AlexNet network and ending with the High-Resolution network (HR.Net)., Several published DL review papers have been presented in the last few years., However, all of them have only been addressed one side focusing on one application or topic such as the review of CNN architectures [21], DL for classifcation of plant diseases [22], DL for object detection, [23], DL applications in medical image analysis [24], and etc., Although these reviews present good topics, they do not provide a full understanding of DL topics such as concepts, detailed research gaps, computational tools, and DL applications.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate sentences scores\n",
        "#By creating a Dictionay for sentences and its normalized frequencies\n",
        "\n",
        "sentence_scores = {}                                            #create Dictionary\n",
        "for sent in sentence_tokens:\n",
        "    for word in sent:\n",
        "        if word.text.lower() in word_frequencies.keys():        \n",
        "            if sent not in sentence_scores.keys():              #add word normalized frequencies count in each of these sentences,then with maximum value we are going to find important sentence \n",
        "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "            else:\n",
        "                sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
        "sentence_scores              "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf3gxXU6nL7F",
        "outputId": "b5266860-d16e-4db4-ab9c-08e26bbb638f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Recently, machine learning (ML) has become very widespread in research and has been incorporated in a variety of applications, including text mining, spam detection, video recommendation, image classifcation, and multimedia concept retrieval [1–6].: 2.3529411764705874,\n",
              " Among the diferent ML algorithms, deep learning (DL) is very commonly employed in these applications [7–9].: 1.2941176470588236,\n",
              " Another name for DL is representation learning (RL).: 0.6470588235294118,\n",
              " Te continuing appearance of novel studies in the felds of deep and distributed learning is due to both the unpredictable growth in the ability to obtain data and the amazing progress made in the hardware technologies,: 1.9411764705882353,\n",
              " e.g. High Performance Computing (HPC): 0.23529411764705882,\n",
              " [10].: 0.058823529411764705,\n",
              " DL is derived from the conventional neural network but considerably outperforms its predecessors.: 0.7058823529411765,\n",
              " Moreover, DL employs transformations and graph technologies simultaneously in order to build up multi-layer learning models.: 1.0588235294117647,\n",
              " Te most recently developed DL techniques have obtained good outstanding performance across a variety of applications, including audio and speech processing, visual data processing, natural language processing (NLP), among others [11–14].: 2.470588235294117,\n",
              " Usually, the efectiveness of an ML algorithm is highly dependent on the integrity of the input-data representation.: 1.2352941176470589,\n",
              " It has been shown that a suitable data representation provides an improved performance when compared to a poor data representation.: 2.235294117647059,\n",
              " Tus, a signifcant research trend in ML for many years has been feature engineering, which has informed numerous research studies.: 1.5294117647058825,\n",
              " Tis approach aims at constructing features from raw data.: 1.0588235294117647,\n",
              " In addition, it is extremely feld-specifc and frequently requires sizable human efort.: 1.0,\n",
              " For instance, several types of features were introduced and compared in the computer vision context, such as, histogram of oriented gradients (HOG): 1.1176470588235294,\n",
              " [15], scaleinvariant feature transform (SIFT): 0.4117647058823529,\n",
              " [16], and bag of words (BoW): 0.1764705882352941,\n",
              " [17].: 0.058823529411764705,\n",
              " As soon as a novel feature is introduced and is found to perform well, it becomes a new research direction that is pursued over multiple decades.: 1.2941176470588236,\n",
              " Relatively speaking, feature extraction is achieved in an automatic way throughout the DL algorithms.: 0.7058823529411765,\n",
              " Tis encourages researchers to extract discriminative features using the smallest possible amount of human efort and feld knowledge [18].: 1.647058823529412,\n",
              " Tese algorithms have a multi-layer data representation architecture, in which the frst layers extract the low-level features while the last layers extract the high-level features.: 3.1764705882352944,\n",
              " Note that artifcial intelligence (AI) originally inspired this type of architecture, which simulates the process that occurs in core sensorial regions within the human brain.: 1.4705882352941178,\n",
              " Using diferent scenes, the human brain can automatically extract data representation.: 1.8823529411764706,\n",
              " More specifcally, the output of this process is the classifed objects, while the received scene information represents the input.: 0.7647058823529412,\n",
              " Tis process simulates the working methodology of the human brain.: 0.9411764705882354,\n",
              " Tus, it emphasizes the main beneft of DL.: 0.35294117647058826,\n",
              " In the feld of ML, DL, due to its considerable success, is currently one of the most prominent research trends.: 0.823529411764706,\n",
              " In this paper, an overview of DL is presented that adopts various perspectives such as the main concepts, architectures, challenges, applications, computational tools and evolution matrix.: 1.647058823529412,\n",
              " Convolutional neural network (CNN) is one of the most popular and used of DL networks [19, 20].: 0.6470588235294118,\n",
              " Because of CNN, DL is very popular nowadays.: 0.1764705882352941,\n",
              " Te main advantage of CNN compared to its predecessors is that it automatically detects the signifcant features without any human supervision which made it the most used.: 1.647058823529412,\n",
              " Terefore, we have dug in deep with CNN by presenting the main Alzubaidi et al.: 0.6470588235294118,\n",
              " J Big Data (2021): 0.5294117647058824,\n",
              " 8:53 Page 3 of 74 components of it.: 0.23529411764705882,\n",
              " Furthermore, we have elaborated in detail the most common CNN architectures, starting with the AlexNet network and ending with the High-Resolution network (HR.Net).: 1.0,\n",
              " Several published DL review papers have been presented in the last few years.: 0.47058823529411764,\n",
              " However, all of them have only been addressed one side focusing on one application or topic such as the review of CNN architectures [21], DL for classifcation of plant diseases [22], DL for object detection: 1.0588235294117647,\n",
              " [23], DL applications in medical image analysis [24], and etc.: 0.7647058823529412,\n",
              " Although these reviews present good topics, they do not provide a full understanding of DL topics such as concepts, detailed research gaps, computational tools, and DL applications.: 1.7647058823529413}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Can tweek percentage\n",
        "# Get 30% of important sentences with maximum score - using nlargest\n",
        "from heapq import nlargest\n",
        "select_length = int(len(sentence_tokens)*0.3)\n",
        "select_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-e_ibvCnWQZ",
        "outputId": "20740183-bad0-4076-b6a1-fb9a2dabe28b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = nlargest(select_length , sentence_scores , key = sentence_scores.get)\n",
        "summary   # Got 4 important sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL_FxCHhnbsD",
        "outputId": "b39a6a93-7d09-4ec9-d5d4-23a85d4d2dfc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tese algorithms have a multi-layer data representation architecture, in which the frst layers extract the low-level features while the last layers extract the high-level features.,\n",
              " Te most recently developed DL techniques have obtained good outstanding performance across a variety of applications, including audio and speech processing, visual data processing, natural language processing (NLP), among others [11–14].,\n",
              " Recently, machine learning (ML) has become very widespread in research and has been incorporated in a variety of applications, including text mining, spam detection, video recommendation, image classifcation, and multimedia concept retrieval [1–6].,\n",
              " It has been shown that a suitable data representation provides an improved performance when compared to a poor data representation.,\n",
              " Te continuing appearance of novel studies in the felds of deep and distributed learning is due to both the unpredictable growth in the ability to obtain data and the amazing progress made in the hardware technologies,,\n",
              " Using diferent scenes, the human brain can automatically extract data representation.,\n",
              " Although these reviews present good topics, they do not provide a full understanding of DL topics such as concepts, detailed research gaps, computational tools, and DL applications.,\n",
              " Tis encourages researchers to extract discriminative features using the smallest possible amount of human efort and feld knowledge [18].,\n",
              " In this paper, an overview of DL is presented that adopts various perspectives such as the main concepts, architectures, challenges, applications, computational tools and evolution matrix.,\n",
              " Te main advantage of CNN compared to its predecessors is that it automatically detects the signifcant features without any human supervision which made it the most used.,\n",
              " Tus, a signifcant research trend in ML for many years has been feature engineering, which has informed numerous research studies.,\n",
              " Note that artifcial intelligence (AI) originally inspired this type of architecture, which simulates the process that occurs in core sensorial regions within the human brain.]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_summary = [word.text for word in summary]\n",
        "final_summary "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TELuWv8nhZU",
        "outputId": "fb018fa3-64d6-4d65-cc71-637be2bcd45b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Tese algorithms have a multi-layer data representation architecture, in which the frst layers extract the low-level features while the last layers extract the high-level features.',\n",
              " 'Te most recently developed DL techniques have obtained good outstanding performance across a variety of applications, including audio and speech processing, visual data processing, natural language processing (NLP), among others [11–14].',\n",
              " 'Recently, machine learning (ML) has become very widespread in research and has been incorporated in a variety of applications, including text mining, spam detection, video recommendation, image classifcation, and multimedia concept retrieval [1–6].',\n",
              " 'It has been shown that a suitable data representation provides an improved performance when compared to a poor data representation.',\n",
              " 'Te continuing appearance of novel studies in the felds of deep and distributed learning is due to both the unpredictable growth in the ability to obtain data and the amazing progress made in the hardware technologies,',\n",
              " 'Using diferent scenes, the human brain can automatically extract data representation.',\n",
              " 'Although these reviews present good topics, they do not provide a full understanding of DL topics such as concepts, detailed research gaps, computational tools, and DL applications.',\n",
              " 'Tis encourages researchers to extract discriminative features using the smallest possible amount of human efort and feld knowledge [18].',\n",
              " 'In this paper, an overview of DL is presented that adopts various perspectives such as the main concepts, architectures, challenges, applications, computational tools and evolution matrix.',\n",
              " 'Te main advantage of CNN compared to its predecessors is that it automatically detects the signifcant features without any human supervision which made it the most used.',\n",
              " 'Tus, a signifcant research trend in ML for many years has been feature engineering, which has informed numerous research studies.',\n",
              " 'Note that artifcial intelligence (AI) originally inspired this type of architecture, which simulates the process that occurs in core sensorial regions within the human brain.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-qfvgJqneQL",
        "outputId": "d043eeef-391e-4d50-a801-098a71b992a2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#combining above 4 lines togeather to from a summary\n",
        "summary = ' ' .join(final_summary)\n",
        "summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "tJMGoDhGnvHu",
        "outputId": "7dcd9f86-9622-4d3a-be87-a423266fd792"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tese algorithms have a multi-layer data representation architecture, in which the frst layers extract the low-level features while the last layers extract the high-level features. Te most recently developed DL techniques have obtained good outstanding performance across a variety of applications, including audio and speech processing, visual data processing, natural language processing (NLP), among others [11–14]. Recently, machine learning (ML) has become very widespread in research and has been incorporated in a variety of applications, including text mining, spam detection, video recommendation, image classifcation, and multimedia concept retrieval [1–6]. It has been shown that a suitable data representation provides an improved performance when compared to a poor data representation. Te continuing appearance of novel studies in the felds of deep and distributed learning is due to both the unpredictable growth in the ability to obtain data and the amazing progress made in the hardware technologies, Using diferent scenes, the human brain can automatically extract data representation. Although these reviews present good topics, they do not provide a full understanding of DL topics such as concepts, detailed research gaps, computational tools, and DL applications. Tis encourages researchers to extract discriminative features using the smallest possible amount of human efort and feld knowledge [18]. In this paper, an overview of DL is presented that adopts various perspectives such as the main concepts, architectures, challenges, applications, computational tools and evolution matrix. Te main advantage of CNN compared to its predecessors is that it automatically detects the signifcant features without any human supervision which made it the most used. Tus, a signifcant research trend in ML for many years has been feature engineering, which has informed numerous research studies. Note that artifcial intelligence (AI) originally inspired this type of architecture, which simulates the process that occurs in core sensorial regions within the human brain.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of original text:\",len(text))\n",
        "print(\"length of autosummarization text\",len(summary))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuwGUuoHnvoe",
        "outputId": "0997b983-b546-4aa8-f353-adcdfb07f244"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of original text: 4388\n",
            "length of autosummarization text 2085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mkeUMEuvnyNA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}